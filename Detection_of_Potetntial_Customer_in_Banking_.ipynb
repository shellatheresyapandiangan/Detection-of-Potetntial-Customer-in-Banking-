{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Busines Understanding"
      ],
      "metadata": {
        "id": "DzYl2e5OBk2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bank X adalah salah satu bank yang memiliki basis pelanggan yang terus berkembang. Mayoritas nasabah tersebut merupakan nasabah deposan dengan ukuran simpanan yang bervariasi. Jumlah pelanggan yang juga peminjam (nasabah aset) cukup kecil, dan bank tertarik untuk memperluas basis ini dengan cepat untuk mendatangkan lebih banyak bisnis pinjaman dan dalam prosesnya, menghasilkan lebih banyak melalui bunga pinjaman. Secara khusus, manajemen ingin mencari cara untuk mengubah pelanggan pertanggungjawabannya menjadi pelanggan pinjaman pribadi (sambil mempertahankan mereka sebagai deposan).\n",
        "\n",
        "Kampanye yang dijalankan bank tahun lalu untuk pelanggan deposan menunjukkan tingkat konversi yang sehat dengan keberhasilan lebih dari 9%. Hal ini mendorong departemen pemasaran ritel untuk merancang kampanye dengan target pemasaran yang lebih baik untuk meningkatkan rasio keberhasilan.\n",
        "\n"
      ],
      "metadata": {
        "id": "Bkb4uwpdBngm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Problem of Business"
      ],
      "metadata": {
        "id": "nSjsauVyCM95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebagai Data Scientist di bank X, kita  harus membuat model yang akan membantu departemen pemasaran mengidentifikasi *calon pelanggan yang memiliki kemungkinan lebih tinggi untuk membeli pinjaman.*\n",
        "Maka tim data scientist akan mencoba membagi menajadi problem sebagai berikut ini:\n",
        "Untuk memprediksi apakah pelanggan liabilitas akan membeli pinjaman pribadi atau tidak.\n",
        "   \n",
        "\n",
        "* Menentukan apakah customer akan menerima penawaran pinjaman atau tidak    \n",
        "* Variabel mana yang paling signifikan.\n",
        "*  Segmen pelanggan mana yang harus lebih dibidik.\n",
        "*   Apakah Umur berpengaruh terhadap pembelian pinjaman nasabah?\n",
        "*   Apakah orang dengan pendapatan lebih rendah meminjam pinjaman?\n"
      ],
      "metadata": {
        "id": "vqH_6nBWCQKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "9lvSFMGeC19V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "File Bank_X.xls berisi data 5000 pelanggan. Data tersebut meliputi informasi demografis nasabah (usia, pendapatan, dll), hubungan nasabah dengan bank dan tanggapan nasabah terhadap kampanye pinjaman pribadi terakhir.Hanya 480 (= 9,6%) yang menerima pinjaman pribadi yang ditawarkan kepada mereka pada kampanye sebelumnya. Berikut ini adalah keterangan dari masing-masing kolom yang digunkanan:\n",
        "\n"
      ],
      "metadata": {
        "id": "4S2CReC3EWvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "    ID: ID dari customer\n",
        "    Age: Umur Customer\n",
        "    Experience: Tahun dari profesional experience\n",
        "    Income: Annual income dari customer dalam satuan USD\n",
        "    ZIP Code: Kode Pos\n",
        "    Family: Size of Family from customer\n",
        "    CCAvg:Rata-rata pengeluaran dari credit card(in thousand dollars)\n",
        "    Education: Tingkat Pendidikan. 1: Undergrad; 2: Graduate;3: Advanced/Professional\n",
        "    Mortgage: Value of house mortgage if any. (in thousand dollars)\n",
        "    Personal_Loan: Status personal customer saat ditawarkan pinjama di campign terakhir\n",
        "    Securities_Account: Apakah customer securities account di bank ini?\n",
        "    CD_Account: ApaKAH Customer memiliki seritifkat deposit (CD) account?\n",
        "    Online: Apakah customer memiliki internet banking?\n",
        "    CreditCard: Apakah customer menggunakan kartu kredit dari bank lain?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xdwgSl8RC3G2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maka dari keterangan data tersebut, dan business understanding serta problem maka step-step yang kami lakukan adalah sebagai berikut ini:"
      ],
      "metadata": {
        "id": "NlgCcMUPDDTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation and Data Understanding"
      ],
      "metadata": {
        "id": "yhrUJKhxGdmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Melakukan penginstallan library yang dibutuhkan\n",
        "### Install and IMPORT: ------------------------------------\n",
        "\n",
        "\n",
        "!pip install zipcodes # installing Zipcodes library .\n",
        "\n",
        "\n",
        "import scipy.stats as stats \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipcodes as zcode # to get zipcodes\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "import statsmodels.api as sm\n",
        "#--Sklearn library--\n",
        "# Sklearn package's randomized data splitting function\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn import metrics\n",
        "#AUC ROC curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay #to plot confusion matric\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression #to build the model\n",
        "from sklearn.tree import DecisionTreeClassifier#to build the model\n",
        "\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "pd.set_option('display.max_rows', 300)\n",
        "pd.set_option('display.max_colwidth',400)\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x) \n",
        "# To supress numerical display in scientific notations\n",
        "warnings.filterwarnings('ignore') # To supress warnings\n",
        " # set the background for the graphs\n",
        "plt.style.use('ggplot')"
      ],
      "metadata": {
        "id": "MQUtuxfJHOWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Melakukan pembacaan dataset dari drive\n",
        "\n",
        "df= pd.read_csv('Bank_X.xls')\n",
        "df"
      ],
      "metadata": {
        "id": "uNtOcSlWC1Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari dataframe tersebut/df maka dapat kita lihat kita sudah memasukkan menjadi dataframe dengan shape baris, kolom = 5000,14"
      ],
      "metadata": {
        "id": "hYcn_LNvIyxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Melakukan cek data teratas\n",
        "df.head()"
      ],
      "metadata": {
        "id": "MLGl4kkOI8aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Melakukan cek data terbawah\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "vW4z-0uuJBZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Melakukan pengecekan size dari dataframe\n",
        "print (\"Rows     : \" , df.shape[0])  #Jumlah Baris\n",
        "print (\"Columns  : \" , df.shape[1]) #Jumlah Kolom\n",
        "print (\"#\"*40,\"\\n\",\"Features : \\n\\n\", df.columns.tolist()) #Melihat nama features\n",
        "print (\"#\"*40,\"\\nMissing values :\\n\\n\", df.isnull().sum().sort_values(ascending=False)) #melihat data null\n",
        "print( \"#\"*40,\"\\nPercent of missing :\\n\\n\", round(df.isna().sum() / df.isna().count() * 100, 2)) # Menjumlahkan jika ada nila Na/null\n",
        "print (\"#\"*40,\"\\nUnique values :  \\n\\n\", df.nunique())  # Melakukan count nilai unik"
      ],
      "metadata": {
        "id": "lGsYroKAJMX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari data tersebut dapat kita validadi bahwa jumlah customer memang benar sebanyak 5000 customer, hal ini dibuktikan nilai uniknya, dan variasi umur ada sekitar 45 variasi, dan lainnya"
      ],
      "metadata": {
        "id": "7xGVlcKiKVKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Semua kolom adalah data numerical, Kolom Personal Loan adalah target yang akan kita prediksi sementara Zipcode,Family,Education,Securities Account,CD_account,online,Credit card adalah variabel yang berpengaruh terhadap variabel yang akan kita prediksi."
      ],
      "metadata": {
        "id": "E96BV6rQK9rK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mari kita melakuka sample terhadap 10 data pertama\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "F7-_dkEdCPKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari dataset diatas, sepertinya index tidak kita butuhkan, maka kita bisa menghapusnya."
      ],
      "metadata": {
        "id": "kmAYQrjyL67o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_UnGdO7A_nl"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "df.drop(['ID'],axis=1,inplace=True) #Menghapus ID\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lalu dari dataset yang ada kita bisa melakukan rename dari variabel yang mengandung spasi sehingga memudahkan dalam mengolahnya."
      ],
      "metadata": {
        "id": "SJYqTynwNReM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={\"ZIP Code\":\"ZIPCode\",\"Personal Loan\":\"PersonalLoan\",\"Securities Account\":\"SecuritiesAccount\",\"CD Account\":'CDAccount'},inplace=True)"
      ],
      "metadata": {
        "id": "JVSgroBCNOXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprosesing"
      ],
      "metadata": {
        "id": "sWtwIEKtMgNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prosesing ZipCode"
      ],
      "metadata": {
        "id": "PqzOY8QYSpVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode pos adalah fitur kategorikal dan dapat menjadi prediktor variabel target yang baik. Kita menganalisis apakah ada pola di lokasi untuk pelanggan yang telah meminjam selama kampanye sebelumnya. Jika memang tidak mempengaruhi maka kita dapat mengurangi variabel prediktornya"
      ],
      "metadata": {
        "id": "e36XP7SZM4zH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.ZIPCode.nunique() #Untuk melihat unik ZIPcode"
      ],
      "metadata": {
        "id": "ZuOeVbsSMfkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari data tersebut dapat kita lihat bahwa dari 5000 customer, ZIPCode unik adalah 467 maka dapat kita asumsikan ada beberapa customer yang memiliki ZipCode yang sama"
      ],
      "metadata": {
        "id": "8bXq7fwhNlli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Untuk mendapatkan data zipcode yang unik\n",
        "zipcode=df.ZIPCode.unique()"
      ],
      "metadata": {
        "id": "kz-c75piOHp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dari zipcode diatas kita bisa melihat daerah tersebut dengan melakukan matching dengan library yang sudah kita install diatas\n",
        "\n",
        "#here i am creating a dictionary of county by using library zipcode and matching method.\n",
        "dict_zip={}\n",
        "for zipcode in zipcode:\n",
        "    my_city_county = zcode.matching(zipcode.astype('str'))\n",
        "    if len(my_city_county)==1: # if  zipcode is present then get county else, assign zipcode to county\n",
        "        county=my_city_county[0].get('county')\n",
        "    else:\n",
        "        county=zipcode\n",
        "    \n",
        "    dict_zip.update({zipcode:county})"
      ],
      "metadata": {
        "id": "Tvrkt_gxOW4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " dict_zip"
      ],
      "metadata": {
        "id": "c_vJd5ohOoKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari library yang digunakan dengan function yang kita setting sudah terdapat daerah berdasarkan zipcode, namun ada bebrapa zipcode yang tidak terdeksi yaitu zipcode 96651,92634,93077,92717. Maka bisa dilakukan pencarian di goole dengan melakukan replace pada hasil yang sudah kita buat dengan replace functio"
      ],
      "metadata": {
        "id": "F-_4De5cPGh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dict_zip.update({92717:'Panyula County'})\n",
        "dict_zip.update({92634:'Fullerton County'})\n",
        "dict_zip.update({96651:'Spain County'})\n",
        "dict_zip.update({93077:'California County'})\n"
      ],
      "metadata": {
        "id": "gvFRNYwaP70S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_zip"
      ],
      "metadata": {
        "id": "7TH437kBQa4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "semua zipcode sudah terisi, maka kita bisa memuat data dari zipcode tadi menjadi kolom baru dari dataset kita dengan metode berikut ini:"
      ],
      "metadata": {
        "id": "dqW51UX1QgwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df['County']=df['ZIPCode'].map(dict_zip)\n",
        "\n"
      ],
      "metadata": {
        "id": "fi7vb9zhQm3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df #melihat dataframe yang sudah kita add"
      ],
      "metadata": {
        "id": "eQY2Mj6bQu46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.County.nunique() #melihat uniq daerah yang sudah kita hasilkan\n",
        "df.info()\n",
        "\n"
      ],
      "metadata": {
        "id": "meyI_WCvRCVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###Memperbaiki Tipe Data\n",
        "\n",
        "Personal_Loan, Securities_Account, CD_Account, 'Online', 'CreditCard' ,Education memiliki tipe data int/object type, maka kita dapat mengganti menjadi object"
      ],
      "metadata": {
        "id": "pd-2NCawRyn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Konversi ke tipe data katgorical\n",
        "newtype = ['PersonalLoan', 'SecuritiesAccount','Family', 'CDAccount', 'Online', 'CreditCard', 'ZIPCode', 'Education','County']\n",
        "df[newtype] = df[newtype].astype('category')\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "wVvLwbDbSFH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df.info()\n",
        "\n"
      ],
      "metadata": {
        "id": "14Y0UOSnSaTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prosesing Experience"
      ],
      "metadata": {
        "id": "K-cl40hkSuwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Experience'].unique()"
      ],
      "metadata": {
        "id": "7hLiA3LFTi8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari data diatas kita bisa melihat bahwa ada nilai experience minus, sehingga kita coba akan melakukan experience minus itu secara average di umur berapa"
      ],
      "metadata": {
        "id": "waIXOfRwTt2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking negative and zero values for experience. \n",
        "df[df['Experience']<0]['Age'].describe()"
      ],
      "metadata": {
        "id": "Tb9DVOxbSw24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari data diatas dapat kita simpulkan bahwa dari 5000 customer, terdapat 52 customer dengan grup umur 23 sampai 29 tahun punya negatif value experience, berikut ini data customer tersebut\n"
      ],
      "metadata": {
        "id": "jzd-b5FsUEg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Experience']<0].sort_values(by='Experience',ascending=True)"
      ],
      "metadata": {
        "id": "NJzfMMIiUWwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['Age','Education'])['Experience'].describe().T"
      ],
      "metadata": {
        "id": "l2-snumxUo0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dari data diatas bisa kita lihat dimulai umur 23 memang experience dari customer memiliki value negatif dibanding umur 40 an."
      ],
      "metadata": {
        "id": "rGv3EBmPUwRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sekarang coba kita lihat dengan 0 experince\n",
        "df[df['Experience']==0]['Age'].describe()"
      ],
      "metadata": {
        "id": "5wI-kOTlVQWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Range usia juga terpait di 24 dan 30"
      ],
      "metadata": {
        "id": "Nqe60-4zVVjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Eksploatory Data Analysis/Descriptive Statistik"
      ],
      "metadata": {
        "id": "mESY57zeVqmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "NVmP_IZsVvr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rata rata customer berumur di 45 tahun dengan nilai experience 20, serta Income 70 USD, maka selanjutnya kita coba akan menghitung unique dari value kita"
      ],
      "metadata": {
        "id": "V0Gu3m5FV1mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column in newtype:\n",
        "    print(df[column].value_counts())\n",
        "    print(\"!\" * 40)"
      ],
      "metadata": {
        "id": "EOvJaom9WcCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insight:\n",
        "\n",
        "    1. Usia pelanggan berkisar antara 23 - 67, dengan rata-rata dan median ~45.\n",
        "    2. Pengalaman maksimal adalah 43 tahun. di mana rata-rata dan median adalah ~20.\n",
        "    3. Penghasilan berada dalam kisaran 8k hingga 224k USD. Rata-rata adalah 73k USD dan median adalah 64k USD. 224 Max gaji perlu diverifikasi\n",
        "    4.Pengeluaran rata-rata untuk kartu kredit per bulan berkisar antara 1- 10k dengan rata-rata 1,9kUSD dan median 1,5k USD\n",
        "    5. 1095 customer berasal dari Los Angeles County.\n",
        "    6. 480 pelanggan telah meminjam pinjaman sebelumnya.\n",
        "    7. >50% Customer sudah menggunakan mobile banking\n",
        "    8. 70% Customer tidak menggunakan credi card\n",
        "    9. dll\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ox0dxLbCXMUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Analisis tiap variabel/Unvariate Analysis"
      ],
      "metadata": {
        "id": "WS5AJ-yHY-oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dist_box(data):\n",
        " #Melakukan pembuata boxplot, dan grafik lain denagn bebera kriteria \n",
        "    Name=data.name.upper()\n",
        "    fig,(ax_box,ax_dis)  =plt.subplots(nrows=2,sharex=True,gridspec_kw = {\"height_ratios\": (.25, .75)},figsize=(8, 5))\n",
        "    mean=data.mean()\n",
        "    median=data.median()\n",
        "    mode=data.mode().tolist()[0]\n",
        "    sns.set_theme(style=\"white\")\n",
        "    fig.suptitle(\"Persebaran dari Data : \"+ Name  , fontsize=30, fontweight='bold')\n",
        "    sns.boxplot(x=data,showmeans=True, orient='h',color=\"violet\",ax=ax_box)\n",
        "    ax_box.set(xlabel='')\n",
        "     # setting backround putih\n",
        "    sns.despine(top=True,right=True,left=True) # menghapus garis samping graph\n",
        "    sns.distplot(data,kde=False,color='blue',ax=ax_dis)\n",
        "    ax_dis.axvline(mean, color='r', linestyle='--',linewidth=2)\n",
        "    ax_dis.axvline(median, color='g', linestyle='-',linewidth=2)\n",
        "    ax_dis.axvline(mode, color='y', linestyle='-',linewidth=2)\n",
        "    plt.legend({'Mean':mean,'Median':median,'Mode':mode})\n",
        "                    "
      ],
      "metadata": {
        "id": "e5lc12OeXL2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kolom yang akan divisualisasikan\n",
        "list_col=  ['Age','Experience','Income','CCAvg','Mortgage']\n",
        "for i in range(len(list_col)):\n",
        "    dist_box(df[list_col[i]])"
      ],
      "metadata": {
        "id": "gAkpraFoZkJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insight\n",
        "\n",
        "    1. Usia dan pengalaman keduanya memiliki Hubungan yang sama\n",
        "    2. Pendapatan condong ke kanan dan memiliki beberapa outlier di sisi yang lebih tinggi yang dapat dipotong.\n",
        "    3. Kredit bulanan rata-rata miring ke kanan dan memiliki banyak "
      ],
      "metadata": {
        "id": "owQSihPUbRhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari kesimpulan diatas kita bisa lihat usia merupakan salah satu pola yang mempengaruhi dari peminjama, maka di sini akan saya lakukan pengelompokan bin usia"
      ],
      "metadata": {
        "id": "hiMQ_PSkcgqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Usia"
      ],
      "metadata": {
        "id": "eV3XQO8Pc7-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Agebin'] = pd.cut(df['Age'], bins = [0, 30, 40, 50, 60, 100], labels = ['18-30', '31-40', '41-50', '51-60', '60-100'])"
      ],
      "metadata": {
        "id": "xwEIbczQcuXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Income\n",
        "\n",
        "Income juga perlu kita bagi berdasarkan dari user seperti berikut ini:"
      ],
      "metadata": {
        "id": "scfPXh4Kc-mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "df[\"Income_group\"] = pd.cut(\n",
        "    x=df[\"Income\"],\n",
        "    bins=[0, 50, 140, 224],\n",
        "    labels=[\"Lower\", \"Middle\", \"High\"],\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "CumDMhvfdBqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Spending\n",
        "Kita juga bisa melakukan grouping spending dari description statistikanya seperti berikut ini:"
      ],
      "metadata": {
        "id": "iBBGdk9Ddaps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.CCAvg.describe()"
      ],
      "metadata": {
        "id": "Yj7jnyo7dklm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df[\"Spending_group\"] = pd.cut( x=df[\"CCAvg\"], bins=[0.00000, 0.70000, 2.50000, 10.00000],\n",
        "    labels=[\"Low\", \"Medium\", \"High\"],include_lowest=True ,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "MYiyb-MXdux5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "setelah melakukan grouping dari berbagai variabel tadi, maka kita sebaiknya melakuakn visualisasi untuk melihat insigt datanya\n",
        "\n",
        "####Visualisasi Data in EDA"
      ],
      "metadata": {
        "id": "TLvEIFl-d08d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a list of all categorical variables\n",
        "cat_columns = ['Family','Education','PersonalLoan','SecuritiesAccount',\n",
        "               'CDAccount','Online','CreditCard','Agebin','Income_group','Spending_group']\n",
        "title=['Jenis Family','Tingkat Pendidikan','Customer ACC Loan',\n",
        "       ' Customer yang memiliki Securities Account','Customers yang memiliki a CD Account',\n",
        "       'Customers  yang transaction Online',' Customers yang memiliki  Credit Card','Grup Umur',\"Grup Pendapatan\",'Grup Amount Yang Ditransaksikan']\n",
        "plt.figure(figsize=(14,20))\n",
        "\n",
        "sns.set_theme(style=\"white\") # just trying to make visualisation better. This will set background to white\n",
        "#list_palette=['Blues_r','Greens_r','Purples_r','Reds_r','Blues_r','Greens_r','Purples_r','Reds_r','Blues_r']\n",
        "\n",
        "for i, variable in enumerate(cat_columns):\n",
        "                     plt.subplot(5,2,i+1)\n",
        "                     order = df[variable].value_counts(ascending=False).index   \n",
        "                     #sns.set_palette(list_palette[i]) # to set the palette\n",
        "                     sns.set_palette('Set2')\n",
        "                     ax=sns.countplot(x=df[variable], data=df )\n",
        "                     sns.despine(top=True,right=True,left=True) # to remove side line from graph\n",
        "                     for p in ax.patches:\n",
        "                           percentage = '{:.1f}%'.format(100 * p.get_height()/len(df[variable]))\n",
        "                           x = p.get_x() + p.get_width() / 2 - 0.05\n",
        "                           y = p.get_y() + p.get_height()\n",
        "                           plt.annotate(percentage, (x, y),ha='center')\n",
        "                     plt.tight_layout()\n",
        "                     plt.title(title[i].upper())\n",
        "                                     "
      ],
      "metadata": {
        "id": "EREdSRixeATi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insight:\n",
        "\n",
        "    1. 29,4% pelanggan lajang.\n",
        "    2. 41,9% pelanggan adalah mahasiswa.\n",
        "    3. 29,4% pelanggan memiliki kartu kredit.\n",
        "    4. 10,4% nasabah memiliki rekening efek di bank\n",
        "    5. 6% pelanggan memiliki akun CD.\n",
        "    6. 60% pelanggan bertransaksi online.\n",
        "    7. 75% pelanggan berada di kisaran 31-60.\n",
        "    8.  50 % Sebagian besar nasabah bank termasuk golongan menengah.\n",
        "    9. 48% pelanggan memiliki pengeluaran rata-rata sedang"
      ],
      "metadata": {
        "id": "P4ygRTi1fG97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####County\n",
        "\n",
        "Melihat daerah mana yang memiliki customer yang melakukan peminjama"
      ],
      "metadata": {
        "id": "C464gXvef7c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,24))\n",
        "\n",
        "pd.crosstab(index=df['County'],columns=df['PersonalLoan'].sort_values(ascending=False)).plot(kind='barh',stacked=True,figsize=(15,24))"
      ],
      "metadata": {
        "id": "tk9iT3qZfs40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari data diatas, berikut ini top 3 daerah yang melakukan pinjaman di bank X:\n",
        "1. Los Angels\n",
        "2. Sandiego\n",
        "3. Santa Clara"
      ],
      "metadata": {
        "id": "8bE5Xx7pfqf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Biavriate/Multivariate Analysis"
      ],
      "metadata": {
        "id": "H1gcVIiRggsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_palette(sns.color_palette(\"Set2\", 8))\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.heatmap(df.corr(),annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XXCuTemugkSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insight:\n",
        "1.  Usia dan pengalaman sangat berkorelasi \n",
        "2. Pendapatan dan pengeluaran rata-rata pada kartu kredit berkorelasi positif."
      ],
      "metadata": {
        "id": "5xcKH7Skg6rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Visualisasi Spending dengan Status Loan\n",
        "sns.relplot(x='Income_group',y='CCAvg',hue='PersonalLoan',data=df)\n",
        "sns.despine(top=True,right=True,left=True) # to remove side line from graph\n",
        "\n"
      ],
      "metadata": {
        "id": "ca-DYVGlhgMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insight : Ketika Spending tinggi, maka rata rata customer akan melakukan loan juga"
      ],
      "metadata": {
        "id": "eKNzRVOZhpB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Age and Loan"
      ],
      "metadata": {
        "id": "wQ6eYmpIhv5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "sns.relplot(x='Age',y='CCAvg',hue='PersonalLoan',data=df)\n",
        "sns.despine(top=True,right=True,left=True) # to remove side line from graph\n",
        "\n"
      ],
      "metadata": {
        "id": "Qv98RtiChzP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Family and loan"
      ],
      "metadata": {
        "id": "z4r0ulDwjrtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "sns.relplot(x='Family',y='CCAvg',hue='PersonalLoan',data=df)\n",
        "sns.despine(top=True,right=True,left=True) # to remove side line from graph\n",
        "\n"
      ],
      "metadata": {
        "id": "WUt-j089juUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loan tertinggi berada di umur 40 an"
      ],
      "metadata": {
        "id": "9_c-dqbViDRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Eduactaion and Status Loan"
      ],
      "metadata": {
        "id": "lYMY4_1QiTZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.swarmplot(x='Education',y='Income',hue='PersonalLoan',data=df)\n",
        "sns.despine(top=True,right=True,left=True) # to remove side line from graph\n",
        "labels=[\"No\",\"Yes\"]\n",
        "plt.legend(loc='lower left', frameon=False,)\n",
        "plt.legend(loc=\"upper left\", labels=labels,title=\"Borrowed Loan\",bbox_to_anchor=(1,1))"
      ],
      "metadata": {
        "id": "yvfMNwH1huU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dari sini kita bisa melihat education tingkat 2 dan 3 melakukan loan"
      ],
      "metadata": {
        "id": "5dNYM1OmifXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Insight of EDA\n",
        "\n",
        "1. Variabel dependen adalah Personal_loan yang bertipe data kategorikal.\n",
        "Age, Experience, Income,mortage ,CCavg bertipe integer sedangkan variabel lainnya bertipe kategoris\n",
        "3. Tidak ada nilai yang hilang dalam kumpulan data.\n",
        "4. Orang dengan pendapatan lebih tinggi telah memilih pinjaman pribadi sebelumnya.\n",
        "5. Jika pelanggan memiliki lebih tinggi rata-rata penggunaan kredit bulanan akan memilih pinjaman.\n",
        "6. Pelanggan dengan Keluarga dari 3/lebih anggota telah meminjam lebih banyak pinjaman dengan bank.\n",
        "7. Tingkat pendidikan 2: Sarjana dan 3: Lanjutan/Professional pernah meminjam ke bank.\n",
        "8. Rasio pinjaman pinjaman tinggi di 30 dan di bawah dan 60 dan di atas pelanggan.\n",
        "9. Semakin banyak pendapatan, semakin banyak membelanjakan dan memiliki gaya hidup \"besar dari kehidupan\".\n",
        "\n",
        "Segmentasi nasabah untuk meminjam pinjaman berdasarkan EDA\n",
        "\n",
        "1. Pelanggan dengan pendapatan lebih tinggi dan pengeluaran rata-rata bulanan yang lebih tinggi. Mereka juga memiliki sertifikat deposito dengan bank. Mereka adalah top customer.\n",
        "2. Beberapa Pelanggan dalam kelompok berpenghasilan menengah, memiliki pengeluaran kartu kredit bulanan yang lebih sedikit. Mereka adalah customer profil rata-rata.\n",
        "3. Pelanggan dalam kelompok berpenghasilan rendah, lebih sedikit pengeluaran bulanan. Mereka adalah customer low profile.\n",
        "\n",
        "Tindakan untuk pra-pemrosesan data:\n",
        "\n",
        "1. Banyak variabel memiliki outlier yang perlu diperlakukan.\n"
      ],
      "metadata": {
        "id": "oeY4zFebjJki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B-6Ih2dqk4vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Outliers Detection"
      ],
      "metadata": {
        "id": "BMqJYNWQlBlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns =['Income','CCAvg','Mortgage','Age']\n",
        "# outlier detection using boxplot\n",
        "plt.figure(figsize=(20,30))\n",
        "\n",
        "for i, variable in enumerate(numeric_columns):\n",
        "                     plt.subplot(4,4,i+1)\n",
        "                     plt.boxplot(df[variable],whis=1.5)\n",
        "                     plt.tight_layout()\n",
        "                     plt.title(variable)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2y00TF8plD6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Income extreme values\n",
        "df.sort_values(by=[\"Income\"],ascending = False).head(5)"
      ],
      "metadata": {
        "id": "p9CC6KqclMiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menambahkan categori regions"
      ],
      "metadata": {
        "id": "wOTRCIMPoZYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counties = {\n",
        "'Los Angeles County':'Los Angeles Region',\n",
        "'San Diego County':'Southern',\n",
        "'Santa Clara County':'Bay Area',\n",
        "'Alameda County':'Bay Area',\n",
        "'Orange County':'Southern',\n",
        "'San Francisco County':'Bay Area',\n",
        "'San Mateo County':'Bay Area',\n",
        "'Sacramento County':'Central',\n",
        "'Santa Barbara County':'Southern',\n",
        "'Yolo County':'Central',\n",
        "'Monterey County':'Bay Area',            \n",
        "'Ventura County':'Southern',             \n",
        "'San Bernardino County':'Southern',       \n",
        "'Contra Costa County':'Bay Area',        \n",
        "'Santa Cruz County':'Bay Area',           \n",
        "'Riverside County':'Southern',            \n",
        "'Kern County':'Southern',                 \n",
        "'Marin County':'Bay Area',                \n",
        "'San Luis Obispo County':'Southern',     \n",
        "'Solano County':'Bay Area',              \n",
        "'Humboldt County':'Superior',            \n",
        "'Sonoma County':'Bay Area',                \n",
        "'Fresno County':'Central',               \n",
        "'Placer County':'Central',                \n",
        "'Butte County':'Superior',               \n",
        "'Shasta County':'Superior',                \n",
        "'El Dorado County':'Central',             \n",
        "'Stanislaus County':'Central',            \n",
        "'San Benito County':'Bay Area',          \n",
        "'San Joaquin County':'Central',           \n",
        "'Mendocino County':'Superior',             \n",
        "'Tuolumne County':'Central',                \n",
        "'Siskiyou County':'Superior',              \n",
        "'Trinity County':'Superior',                \n",
        "'Merced County':'Central',                  \n",
        "'Lake County':'Superior',                 \n",
        "'Napa County':'Bay Area',                   \n",
        "'Imperial County':'Southern',\n",
        "93077:'Southern',\n",
        "96651:'Bay Area'\n",
        "}\n",
        "\n",
        "\n",
        "df['Regions'] = df['County'].map(counties)\n",
        "\n"
      ],
      "metadata": {
        "id": "P9WIOvVgocSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ini adalah beberapa outlier, seperti pendapatan 224K USD.  Setelah mengidentifikasi outlier, maka dapat kita putuskan apakah akan menghapus/memperlakukannya atau tidak. Karena setelah diskusi dengan user itu bisa digunakan maka kita menggunakan untuk melihat potential customer untuk melakukan peminjaman"
      ],
      "metadata": {
        "id": "DIo3qNhileFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Melakukan penghapusan kolom yang tidak kita gunakan"
      ],
      "metadata": {
        "id": "bVKM-04pmCIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.drop(columns=[\"Agebin\", \"ZIPCode\",\"County\",'Experience','Income_group','Spending_group'], inplace=True)"
      ],
      "metadata": {
        "id": "_tVT18sdmGWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = df.drop(['PersonalLoan'], axis=1)\n",
        "Y = df['PersonalLoan']\n",
        "\n",
        "oneHotCols=['Regions','Education']\n",
        "X=pd.get_dummies(X,columns=oneHotCols,drop_first=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "pKotFnvHmecG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split data to Train and Test secara acak"
      ],
      "metadata": {
        "id": "mob2sU2go3g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting data in train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.30, random_state = 1,stratify=Y)"
      ],
      "metadata": {
        "id": "0JWrbUNho8cW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Melakukan Scaling Data"
      ],
      "metadata": {
        "id": "BD5uxHotpC2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# Creating StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fitting Standard Scaller\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scaling data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled,columns=X_train.columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled,columns=X_test.columns)\n",
        "\n",
        "\n",
        "X_train_scaled_df.index=np.arange(len(X_train_scaled_df))\n",
        "X_test_scaled_df.index=np.arange(len(X_test_scaled_df))\n",
        "y_train.index=np.arange(len(y_train))\n",
        "y_test.index=np.arange(len(y_test))"
      ],
      "metadata": {
        "id": "H9oPFkEcpE6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Membangun Model Logistic Regresion"
      ],
      "metadata": {
        "id": "2AdjwlnFpblr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asmsi model akan menghasilkan:\n",
        "\n",
        "Kasus 1. Memprediksi seseorang akan membeli pinjaman tetapi sebenarnya tidak. \n",
        "Kasus 2. Memprediksi seseorang tidak akan membeli pinjaman tetapi actual dia melakukan\n",
        "\n",
        "Kasus mana yang lebih penting?\n",
        "\n",
        "Seluruh tujuan kampanye adalah untuk mendatangkan lebih banyak pelanggan. Kasus ke-2 lebih penting bagi bank. Sehingga pelanggan potensial terlewatkan oleh tim penjualan/pemasaran. \n",
        "\n",
        "Bagaimana cara mengurangi kerugian/peluang tadi ? \n",
        "yaitu perlu mengurangi False Negatif\n",
        "\n",
        "    Dalam hal ini, tidak dapat mengidentifikasi pelanggan potensial adalah kerugian terbesar yang dapat di hadapi bank. Oleh karena itu, penarikan kembali adalah metrik yang tepat untuk memeriksa kinerja model. Bank ingin Inga dimaksimalkan, semakin besar recall, semakin kecil kemungkinan False Negatif(predict negatif, but actual True => False Negatif).\n",
        "\n",
        "Kita dapat menggunakan akurasi, tetapi karena datanya imbalance, ini bukan metrik yang tepat untuk memeriksa kinerja model.\n",
        "\n",
        "    Oleh karena itu, Recall harus dimaksimalkan, semakin besar Recall semakin tinggi peluang mengidentifikasi kedua kelas dengan benar. Maka unsur yang dapat mdigunakan dalam mengevaluasi model di segemntasi customer banking adalah recall"
      ],
      "metadata": {
        "id": "WN2Od99bpfXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_confusion_matrix(y_actual,y_predict,title):\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    \n",
        "    cm = confusion_matrix(y_actual, y_predict, labels=[0,1])\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                               display_labels=[\"No\",\"Yes\"])\n",
        "    disp.plot(cmap='Greens',colorbar=True,ax=ax)\n",
        "    ax.set_title(title)\n",
        "    plt.tick_params(axis=u'both', which=u'both',length=0)\n",
        "    plt.grid(b=None,axis='both',which='both',visible=False)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AhPYsTvQq6VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics_score(model,X_train_df,X_test_df,y_train_pass,y_test_pass,statsklearn,threshold=0.5,flag=True,roc=False):\n",
        "    '''\n",
        "    Function to calculate different metric scores of the model - Accuracy, Recall, Precision, and F1 score\n",
        "    model: classifier to predict values of X\n",
        "    X_train_df, X_test_df: Independent features\n",
        "    y_train_pass,y_test_pass: Dependent variable\n",
        "    statsklearn : 0 if calling for Sklearn model else 1\n",
        "    threshold: thresold for classifiying the observation as 1\n",
        "    flag: If the flag is set to True then only the print statements showing different will be displayed. The default value is set to True.\n",
        "    roc: If the roc is set to True then only roc score will be displayed. The default value is set to False.\n",
        "    '''\n",
        "    # defining an empty list to store train and test results\n",
        "    \n",
        "    score_list=[] \n",
        "    if statsklearn==0:\n",
        "        pred_train = model.predict(X_train_df)\n",
        "        pred_test = model.predict(X_test_df)\n",
        "    else:\n",
        "        pred_train = (model.predict(X_train_df)>threshold)\n",
        "        pred_test = (model.predict(X_test_df)>threshold)\n",
        "    \n",
        "    \n",
        "    pred_train = np.round(pred_train)\n",
        "    pred_test = np.round(pred_test)\n",
        "    \n",
        "    train_acc = accuracy_score(y_train_pass,pred_train)\n",
        "    test_acc = accuracy_score(y_test_pass,pred_test)\n",
        "    \n",
        "    train_recall = recall_score(y_train_pass,pred_train)\n",
        "    test_recall = recall_score(y_test_pass,pred_test)\n",
        "    \n",
        "    train_precision = precision_score(y_train_pass,pred_train)\n",
        "    test_precision = precision_score(y_test_pass,pred_test)\n",
        "    \n",
        "    train_f1 = f1_score(y_train_pass,pred_train)\n",
        "    test_f1 = f1_score(y_test_pass,pred_test)\n",
        "    \n",
        "    \n",
        "    score_list.extend((train_acc,test_acc,train_recall,test_recall,train_precision,test_precision,train_f1,test_f1))\n",
        "      \n",
        "    if flag == True: \n",
        "        print(\"\\x1b[0;30;47m \\033[1mMODEL PERFORMANCE\\x1b[0m\")\n",
        "        print(\"\\x1b[0;30;47m \\033[1mAccuracy   : Train:\\x1b[0m\",\n",
        "              round(accuracy_score(y_train_pass,pred_train),3),\n",
        "              \"\\x1b[0;30;47m \\033[1mTest:\\x1b[0m \",\n",
        "              round(accuracy_score(y_test_pass,pred_test),3))\n",
        "        print(\"\\x1b[0;30;47m \\033[1mRecall     : Train:\\x1b[0m\"\n",
        "              ,round(recall_score(y_train_pass,pred_train),3),\n",
        "              \"\\x1b[0;30;47m \\033[1mTest:\\x1b[0m\" ,\n",
        "              round(recall_score(y_test_pass,pred_test),3))\n",
        "        \n",
        "        print(\"\\x1b[0;30;47m \\033[1mPrecision  : Train:\\x1b[0m\",\n",
        "              round(precision_score(y_train_pass,pred_train),3),\n",
        "              \"\\x1b[0;30;47m \\033[1mTest:\\x1b[0m \",\n",
        "              round(precision_score(y_test_pass,pred_test),3))\n",
        "        print(\"\\x1b[0;30;47m \\033[1mF1         : Train:\\x1b[0m\",\n",
        "              round(f1_score(y_train_pass,pred_train),3),\n",
        "              \"\\x1b[0;30;47m \\033[1mTest:\\x1b[0m\",\n",
        "              round(f1_score(y_test_pass,pred_test),3))\n",
        "        make_confusion_matrix(y_train_pass,pred_train,\"Confusion Matrix for Train\")     \n",
        "        make_confusion_matrix(y_test_pass,pred_test,\"Confusion Matrix for Test\") \n",
        "   \n",
        "    if roc == True:\n",
        "        \n",
        "        print(\"\\x1b[0;30;47m \\033[1mROC-AUC Score  :Train:\\x1b[0m: \",\n",
        "              round(roc_auc_score(y_train_pass,pred_train),3),\n",
        "              \"\\x1b[0;30;47m \\033[1mTest:\\x1b[0m: \",\n",
        "              round(roc_auc_score(y_test_pass,pred_test),3))\n",
        "    \n",
        "    return score_list # returning the list with train and test scores"
      ],
      "metadata": {
        "id": "9AYbVEVwrF-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # defining empty lists to add train and test results\n",
        "acc_train = []\n",
        "acc_test = []\n",
        "recall_train = []\n",
        "recall_test = []\n",
        "precision_train = []\n",
        "precision_test = []\n",
        "f1_train = []\n",
        "f1_test = []\n",
        "\n",
        "def add_score_model(score):\n",
        "     '''Add scores to list so that we can compare all models score together'''   \n",
        "     acc_train.append(score[0])\n",
        "     acc_test.append(score[1])\n",
        "     recall_train.append(score[2])\n",
        "     recall_test.append(score[3])\n",
        "     precision_train.append(score[4])\n",
        "     precision_test.append(score[5])\n",
        "     f1_train.append(score[6])\n",
        "     f1_test.append(score[7])"
      ],
      "metadata": {
        "id": "8wYAYwMJrRJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistik with SKLEARN LIB\n",
        "lr = LogisticRegression(solver='newton-cg',random_state=1,fit_intercept=False,class_weight={0:0.15,1:0.85})\n",
        "model  = lr.fit(X_train_scaled_df,y_train)\n",
        "\n",
        "statmodel=0  #0 for sklearn and 1 for statmodel\n",
        "\n",
        "# Let's check model performances for this model\n",
        "scores_Sklearn = get_metrics_score(model,X_train_scaled_df,X_test_scaled_df,y_train,y_test,statmodel)"
      ],
      "metadata": {
        "id": "QMZ04cIdrZHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Logistik Regression with stat Model"
      ],
      "metadata": {
        "id": "QVS7wCTjsoT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adding constant to training and test set\n",
        "X_train_stat = sm.add_constant(X_train_scaled_df)\n",
        "X_test_stat = sm.add_constant(X_test_scaled_df)\n",
        "statmodel=1  #0 for sklearn and 1 for statmodel\n",
        "logit = sm.Logit( y_train, X_train_stat.astype(float) )\n",
        "lg = logit.fit(warn_convergence=False)\n",
        "\n",
        "# Let's check model performances for this model\n",
        "scores_statmodel = get_metrics_score(lg,X_train_stat,X_test_stat,y_train,y_test,statmodel)\n",
        "lg.summary() "
      ],
      "metadata": {
        "id": "ehiTav85ssxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decision Tree"
      ],
      "metadata": {
        "id": "DOTMUFeEuLt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop column which we don't need for modelling\n",
        "df.drop(columns=[\"Agebin\", \"ZIPCode\",\"County\",'Experience','Income_group','Spending_group'], inplace=True)"
      ],
      "metadata": {
        "id": "kyXSFCtqt91J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_dt = df.drop('PersonalLoan', axis=1)\n",
        "y_dt = df['PersonalLoan']"
      ],
      "metadata": {
        "id": "e2bSD5n4v8IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#oneHotCols=['Regions']\n",
        "oneHotCols=X_dt.select_dtypes(exclude='number').columns.to_list()\n",
        "X_dt=pd.get_dummies(X_dt,columns=oneHotCols,drop_first=True)\n",
        "# Spliting data set\n",
        "X_train_dt, X_test_dt, y_train_dt, y_test_dt = train_test_split(X_dt, y_dt, test_size=0.3, random_state=1, stratify=y_dt)\n",
        "\n"
      ],
      "metadata": {
        "id": "h_Lp72cRuC73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Memabngun Models"
      ],
      "metadata": {
        "id": "gXbJ-DauwDZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##  Function to calculate recall score\n",
        "def get_recall_score(model):\n",
        "    '''\n",
        "    model : classifier to predict values of X\n",
        "\n",
        "    '''\n",
        "    ytrain_predict = model.predict(X_train_dt)\n",
        "    ytest_predict = model.predict(X_test_dt)\n",
        "    # accuracy on training set\n",
        "    print(\"\\x1b[0;30;47m \\033[1mAccuracy : Train :\\033[0m\", \n",
        "          model.score(X_train_dt,y_train_dt),\n",
        "          \"\\x1b[0;30;47m \\033[1mTest:\\033[0m\", \n",
        "          model.score(X_test_dt,y_test_dt))\n",
        "# accuracy on training set\n",
        "    print(\"\\x1b[0;30;47m \\033[1mRecall   : Train :\\033[0m\", \n",
        "          metrics.recall_score(y_train_dt,ytrain_predict),\n",
        "          \"\\x1b[0;30;47m \\033[1mTest:\\033[0m\", \n",
        "          metrics.recall_score(y_test_dt,ytest_predict))\n",
        "    make_confusion_matrix(y_train_dt,ytrain_predict,\"Confusion Matric on Train Data\")\n",
        "    make_confusion_matrix(y_test_dt,ytest_predict,\"Confusion Matric on Test Data\")"
      ],
      "metadata": {
        "id": "PrH1e9aqwQjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since data is imbalanced adding weights\n",
        "model = DecisionTreeClassifier(criterion = 'gini',class_weight={0:0.15,1:0.85}, random_state=1)\n",
        "model.fit(X_train_dt, y_train_dt)\n",
        "get_recall_score(model)"
      ],
      "metadata": {
        "id": "cA_yDPWxwWRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "column_names = list(X_dt.columns)\n",
        "feature_names = column_names\n",
        "print(feature_names)\n",
        "\n"
      ],
      "metadata": {
        "id": "Qhi1bUNYwZ40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(20,30))\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "out = tree.plot_tree(model,feature_names=feature_names,filled=True,fontsize=9,node_ids=True,class_names=True)\n",
        "for o in out:\n",
        "     arrow = o.arrow_patch\n",
        "     if arrow is not None:\n",
        "        arrow.set_edgecolor('black')\n",
        "        arrow.set_linewidth(1)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "QULwjZuKwdrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Melakukan Deteksi Features Imporatnce"
      ],
      "metadata": {
        "id": "YlGZGfKuwoKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances = model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='purple', align='center')\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zwCl8aibwsRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terlalu banyak pohon keputusan, sehingga kita bisa melakukan tuning terhadap parameter yang berlebih ini/hyperparameter tuning denagn metode GridSearch dibawah ini:"
      ],
      "metadata": {
        "id": "-Hoi5j1-xdbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the type of classifier. \n",
        "estimator = DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "# Grid of parameters to choose from\n",
        "\n",
        "parameters = {'max_depth': np.arange(1,10), \n",
        "              'min_samples_leaf': [1, 2, 5, 7, 10,15,20],\n",
        "              'max_leaf_nodes' : [5, 10,15,20,25,30],\n",
        "              }\n",
        "\n",
        "# Type of scoring used to compare parameter combinations\n",
        "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
        "\n",
        "# Run the grid search\n",
        "grid_obj = GridSearchCV(estimator, parameters, scoring=acc_scorer,cv=5)\n",
        "grid_obj = grid_obj.fit(X_train_dt, y_train_dt)\n",
        "\n",
        "# Set the clf to the best combination of parameters\n",
        "estimator = grid_obj.best_estimator_\n",
        "estimator"
      ],
      "metadata": {
        "id": "8AEBk1-Nx0U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the best algorithm to the data. \n",
        "estimator.fit(X_train_dt, y_train_dt)\n",
        "ytrain_predict=estimator.predict(X_train_dt)\n",
        "ytest_predict=estimator.predict(X_test_dt)"
      ],
      "metadata": {
        "id": "3cHVToIayCjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "out = tree.plot_tree(estimator,feature_names=feature_names,filled=True,fontsize=9,node_ids=False,class_names=True)\n",
        "for o in out:\n",
        "    arrow = o.arrow_patch\n",
        "    if arrow is not None:\n",
        "        arrow.set_edgecolor('black')\n",
        "        arrow.set_linewidth(1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cIIIKRKnyGBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = estimator.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='violet', align='center')\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1btlpawZyKA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "get_recall_score(estimator)\n",
        "\n"
      ],
      "metadata": {
        "id": "eKllOJIxyQ_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insigt :\n",
        "\n",
        "Dengan HyperParameter max_depth=6, max_leaf_nodes=20, min_samples_leaf=7 overfitting pada kereta telah berkurang, tetapi penarikan kembali untuk pengujian belum membaik.\n",
        "  \n",
        "  Fitur penting adalah Penghasilan, Eduaction,Family CCavg & Umur.\n",
        "    Namun metrik penarikan masih 84 dari testing dan negatif palsu 23. Sebagagai perusahaan pastinya kita tidak ingin kehilangan peluang dalam memprediksi pelanggan ini. jadi Mari kita lihat apakah alih-alih pre pruning , post pruning membantu mengurangi false negative."
      ],
      "metadata": {
        "id": "py4qtnZUyhVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Pruning"
      ],
      "metadata": {
        "id": "ry-TFSBczPgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zTX8xNeKzSlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(random_state=1)\n",
        "path = clf.cost_complexity_pruning_path(X_train_dt, y_train_dt)\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
      ],
      "metadata": {
        "id": "ZFa22zofzkCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,5))\n",
        "ax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
        "ax.set_xlabel(\"effective alpha\")\n",
        "ax.set_ylabel(\"total impurity of leaves\")\n",
        "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "vP5M6tE6zlJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya, cara ini melatih pohon keputusan menggunakan alpha yang efektif dan akan menetapkan nilai alpha ini dan meneruskannya ke parameter ccp_alpha dari DecisionTreeClassifier. Kita dapat meningkatan keakuratan train and test dengan metode ini"
      ],
      "metadata": {
        "id": "jqCEyB2Rz5ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clfs = []\n",
        "accuracy_train=[]\n",
        "accuracy_test=[]\n",
        "recall_train=[]\n",
        "recall_test=[]\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=1, ccp_alpha=ccp_alpha,class_weight = {0:0.15,1:0.85})\n",
        "    clf.fit(X_train_dt, y_train_dt)\n",
        "    y_train_pred=clf.predict(X_train_dt)\n",
        "    y_test_pred=clf.predict(X_test_dt)\n",
        "    accuracy_train.append(clf.score(X_train_dt,y_train_dt))\n",
        "    accuracy_test.append(clf.score(X_test_dt,y_test_dt))\n",
        "    recall_train.append(metrics.recall_score(y_train_dt,y_train_pred))\n",
        "    recall_test.append(metrics.recall_score(y_test_dt,y_test_pred))\n",
        "    clfs.append(clf)"
      ],
      "metadata": {
        "id": "r2bW3ql20M34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,5))\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"Recall\")\n",
        "ax.set_title(\"Recall vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas, recall_train, marker='o', label=\"train\",\n",
        "        drawstyle=\"steps-post\")\n",
        "ax.plot(ccp_alphas, recall_test, marker='o', label=\"test\",\n",
        "        drawstyle=\"steps-post\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "q0NPzBNs0UwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kita dapat melihat alpha sekitar 0.002 s/d 0.005 kita pilih 0.01"
      ],
      "metadata": {
        "id": "qEiJSiAVz5o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = DecisionTreeClassifier(ccp_alpha=0.002,\n",
        "                       class_weight={0: 0.15, 1: 0.85}, random_state=1)\n",
        "best_model.fit(X_train_dt, y_train_dt)"
      ],
      "metadata": {
        "id": "Q1Mq0j2x0v3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "get_recall_score(best_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "l14tcxMD1EWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "\n",
        "out = tree.plot_tree(best_model,feature_names=feature_names,filled=True,fontsize=9,node_ids=False,class_names=True)\n",
        "for o in out:\n",
        "    arrow = o.arrow_patch\n",
        "    if arrow is not None:\n",
        "        arrow.set_edgecolor('black')\n",
        "        arrow.set_linewidth(1)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "qbE2moiQ1kZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "importances = best_model.feature_importances_\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "plt.title('Feature Importances')\n",
        "plt.barh(range(len(indices)), importances[indices], color='violet', align='center')\n",
        "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "V35nZtp91rI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Insight:\n",
        "Dari best model kita peroleh recall bagus ketika alpha di 0.002, sehingga kita cova alpha 0.003 dan menghasilkan akurasi recall 96% dan mengurangi FN dari 21 menjadi 6 yang artinya semakin kecil resiko kehilangan potensial customer yang akan melakukan transaksi ke kita.\n"
      ],
      "metadata": {
        "id": "9Li55hri1f8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparison semua model"
      ],
      "metadata": {
        "id": "y6a-ofC42OTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_frame = pd.DataFrame({'Model':['scores_statmodel',\n",
        "                                          'Initial decision tree model',\n",
        "                                          'Decision treee with hyperparameter tuning',\n",
        "                                          'Decision tree with post-pruning'], \n",
        "                                          'Train_accuracy':[0.92,1,0.99,0.98],\n",
        "                                          'Test_accuracy':[0.91,0.98,0.98,0.97],\n",
        "                                          'Train_Recall':[0.90,1,0.92,0.98], \n",
        "                                          'Test_Recall':[0.88,0.86,0.84,0.96]})  \n",
        "\n",
        "comparison_frame"
      ],
      "metadata": {
        "id": "Ry9DsQrS2JAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(X_test_dt)\n",
        "print(classification_report(y_test_dt,y_pred))\n",
        "make_confusion_matrix(y_test,y_pred,\"confusion matrix on test\")"
      ],
      "metadata": {
        "id": "yeE-NFNT3655"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model decision tree with prooning telah memberi kami skor ingatan terbaik pada data dengan akurasi 96%. Analisis data eksplorasi juga menyarankan income and education merupakan fitur penting dalam memutuskan apakah seseorang akan meminjam pinjaman pribadi. Jadi dari semua model lebih baik menggunakan decision tree dengan alpha 0.002 atau setelah prooning untuk dataset ini."
      ],
      "metadata": {
        "id": "GJl7nfxp3cUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kesimpulan\n",
        "\n",
        "1. Data digunakan untuk menganalisis data promosi Pinjaman Pribadi menggunakan EDA dan dengan menggunakan model yang berbeda seperti Regresi Logistik dan Decision Tree Keputusan untuk membangun kemungkinan Pelanggan membeli Pinjaman.\n",
        "2. Pertama sebaiknya membangun model menggunakan Regresi Logistik dan metrik kinerja yang digunakan adalah Recall. Fitur yang paling penting untuk klasifikasi adalah Pendapatan, Pendidikan, Keluarga dan CCAvg .\n",
        "3. Koefisien Pendapatan, Lulusan dan Pendidikan, Family_3,Family 4,CCavg,CD account,Usia, adalah positif , yaitu peningkatan satu unit dalam hal ini akan meningkatkan peluang seseorang untuk meminjam pinjaman\n",
        "4. Tim DS Bank X menyarankan menggunakan decision tree dengan prepruning dan post pruning. Model Post pruning memberikan 96% recall dengan akurasi 97%.\n",
        "5. Penghasilan, Pelanggan dengan gelar sarjana, pelanggan yang memiliki 3 anggota keluarga adalah beberapa variabel terpenting dalam memprediksi apakah pelanggan akan membeli pinjaman pribadi."
      ],
      "metadata": {
        "id": "yhp3-kwV4Oki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Recomendation And Actionable"
      ],
      "metadata": {
        "id": "JqMtV0LH5WEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Pohon keputusan tidak memerlukan banyak persiapan data atau penanganan outlier seperti regresi logistik. Mereka mudah dimengerti. Pohon keputusan dapat dengan mudah overfit(perilaku pembelajaran mesin yang tidak diinginkan yang terjadi ketika model pembelajaran mesin memberikan prediksi akurat untuk data pelatihan tetapi tidak untuk data baru/testing) , jadi kita harus berhati-hati menggunakan pohon keputusan.\n",
        "2. Berdasarkan EDA, Logistic Regression , Decision tree , Income ,Educatoin,Family,CCavg merupakan faktor yang paling penting.\n",
        "3. Pelanggan yang memiliki pendapatan di atas 98k dolar , Pendidikan tingkat lanjut / sarjana, keluarga lebih dari 2, pelanggan tersebut memiliki peluang lebih tinggi untuk mengambil pinjaman pribadi.\n",
        "Jadi untuk kampanye ini kami dapat memiliki profil yang berbeda untuk pelanggan.\n",
        "   \n",
        "Action to Customer:\n",
        "\n",
        "1. Klien Profil Tinggi:-Pendapatan lebih tinggi,Pendidikan tingkat lanjut/Sarjana, 3/4 anggota keluarga,belanja tinggi\n",
        "2. Profil Rata-Rata :- Kelompok berpendapatan sedang, Pendidikan tingkat S2.3/4 Anggota keluarga, Pengeluaran sedang\n",
        "3. Profil Rendah:-Kelompok berpenghasilan rendah, sarjana, 3/4 Anggota Keluarga, pengeluaran rendah\n",
        "\n",
        "Pertama-tama, tim DS menyarankan dapat menargetkan pelanggan profil tinggi, dengan memberi mereka customer relationship yang dapat menangani masalah di sana dan dapat mengejar mereka untuk membeli pinjaman dari bank dengan suku bunga lengkap.\n",
        "Target kedua adalah pelanggan profil Menengah.\n"
      ],
      "metadata": {
        "id": "o579X4w25ZXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thankyou----"
      ],
      "metadata": {
        "id": "-USwltsb6IZa"
      }
    }
  ]
}